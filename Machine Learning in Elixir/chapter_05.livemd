# Machine Learning in Elixir Chapter 05

```elixir
# scholar: traditional machine learning tools
# nx: array operation
# exla: Google's XLA (Accelerated Linear Algebra) compiler/backend for Nx
# kino_vega_lite: draw graph in livebook
# scidata: dataset

Mix.install([
  {:scholar, "~> 0.2.0"},
  {:nx, "~> 0.5"},
  {:exla, "~> 0.5"},
  {:vega_lite, "~> 0.1.6"},
  {:kino_vega_lite, "~> 0.1.6"},
  {:scidata, "~> 0.1"}
])
```

## Section

```elixir
# setup default backend
# setup default compiler

Nx.default_backend(EXLA.Backend)
Nx.Defn.default_options(compiler: EXLA)
```

```elixir
# create training data

m = :rand.uniform() * 10
b = :rand.uniform() * 10

key = Nx.Random.key(42)
size = 100
{x, new_key} = Nx.Random.normal(key, 0.0, 1.0, shape: {size, 1})
{noise_x, new_key} = Nx.Random.normal(new_key, 0.0, 1.0, shape: {size, 1})

y =
  m
  |> Nx.multiply(Nx.add(x, noise_x))
  |> Nx.add(b)
```

```elixir
# visualize the training data

alias VegaLite, as: Vl

Vl.new(title: "Scatterplot", width: 720, height: 480)
|> Vl.data_from_values(%{
  x: Nx.to_flat_list(x),
  y: Nx.to_flat_list(y)
})
|> Vl.mark(:point)
|> Vl.encode_field(:x, "x", type: :quantitative)
|> Vl.encode_field(:y, "y", type: :quantitative)
```

```elixir
# create a linear regression model

model = Scholar.Linear.LinearRegression.fit(x, y)
```

```elixir
# use the model to predict 

Scholar.Linear.LinearRegression.predict(model, Nx.iota({3, 1}))
```

```elixir
# try to draw model overlay training data

pred_xs = Nx.linspace(-3.0, 3.0, n: 100) |> Nx.new_axis(-1)
pred_ys = Scholar.Linear.LinearRegression.predict(model, pred_xs)
```

```elixir
# draw predition overlay training data

title = "Scatterplot Distribution and Fit Curve"

Vl.new(title: title, width: 720, height: 480)
|> Vl.data_from_values(%{
  x: Nx.to_flat_list(x),
  y: Nx.to_flat_list(y),
  pred_x: Nx.to_flat_list(pred_xs),
  pred_y: Nx.to_flat_list(pred_ys)
})
|> Vl.layers([
  Vl.new()
  |> Vl.mark(:point)
  |> Vl.encode_field(:x, "x", type: :quantitative)
  |> Vl.encode_field(:y, "y", type: :quantitative),
  Vl.new()
  |> Vl.mark(:line)
  |> Vl.encode_field(:x, "pred_x", type: :quantitative)
  |> Vl.encode_field(:y, "pred_y", type: :quantitative)
])
```

```elixir
# download data

{inputs, targets} = Scidata.Wine.download()
```

```elixir
# split data to training_set and testing_set 

{train, test} = 
  inputs   
  |> Enum.zip(targets)   
  |> Enum.shuffle()   
  |> Enum.split(floor(length(inputs) * 0.8))

# convert training_set to NX format

{train_inputs, train_targets} = Enum.unzip(train) 
train_inputs = Nx.tensor(train_inputs) 
train_targets = Nx.tensor(train_targets)  

# convert testing_set to NX format

{test_inputs, test_targets} = Enum.unzip(test) 
test_inputs = Nx.tensor(test_inputs) 
test_targets = Nx.tensor(test_targets)
```

```elixir
# normalize the data to 0..1

train_inputs = Scholar.Preprocessing.min_max_scale(train_inputs)
test_inputs = Scholar.Preprocessing.min_max_scale(test_inputs)
```

```elixir
# training the model with LogisticRegression algorithm

model = Scholar.Linear.LogisticRegression.fit(
  train_inputs, 
  train_targets, 
  num_classes: 3
)
```

```elixir
# test the model with testing data

test_preds = Scholar.Linear.LogisticRegression.predict(model, test_inputs)
```

```elixir
# find accuracy of the model

Scholar.Metrics.Classification.accuracy(test_targets, test_preds)
```

```elixir
# use confusion_matrix to evaluate the model

Scholar.Metrics.Classification.confusion_matrix(
  test_targets,
  test_preds,
  num_classes: 3
)
```

```elixir
# visualize the confusion_matrix result

Vl.new(
  title: "Confusion Matrix",
  width: 1440,
  height: 1080
)
|> Vl.data_from_values(%{
  predicted: Nx.to_flat_list(test_preds),
  actual: Nx.to_flat_list(test_targets)
})
|> Vl.mark(:rect)
|> Vl.encode_field(:x, "predicted")
|> Vl.encode_field(:y, "actual")
|> Vl.encode(:color, aggregate: :count)
```

```elixir
# training the model with KNearestNeighbors algorithm

model = Scholar.Neighbors.KNearestNeighbors.fit(
  train_inputs, 
  train_targets, 
  num_classes: 3
)
```

```elixir
# use the model to predict

test_preds = Scholar.Neighbors.KNearestNeighbors.predict(model, test_inputs)
```

```elixir
# evaluate the model accuracy

Scholar.Metrics.Classification.accuracy(test_targets, test_preds)
```

```elixir
# evaluate the model with confusion_matrix

Scholar.Metrics.Classification.confusion_matrix(test_targets, test_preds, num_classes: 3)
```

```elixir
# train a model with KMeans algorithm

model = Scholar.Cluster.KMeans.fit(train_inputs, num_clusters: 3)
```

```elixir
# visualize the training result

wine_features = %{
  "feature_1" => train_inputs[[.., 1]] |> Nx.to_flat_list(),
  "feature_2" => train_inputs[[.., 2]] |> Nx.to_flat_list(),
  "class" => train_targets |> Nx.to_flat_list()
}

coords = [
  cluster_feature_1: model.clusters[[.., 1]] |> Nx.to_flat_list(),
  cluster_feature_2: model.clusters[[.., 2]] |> Nx.to_flat_list()
]

title = "Scatterplot of data samples projected on plane wine feature 1 x wine feature 2"

Vl.new(
  width: 1440,
  height: 1080,
  title: [
    text: title,
    offset: 25
  ]
)
|> Vl.layers([
  Vl.new()
  |> Vl.data_from_values(wine_features)
  |> Vl.mark(:circle)
  |> Vl.encode_field(:x, "feature_1", type: :quantitative)
  |> Vl.encode_field(:y, "feature_2", type: :quantitative)
  |> Vl.encode_field(:color, "class"),
  Vl.new()
  |> Vl.data_from_values(coords)
  |> Vl.mark(:circle, color: :green, size: 100)
  |> Vl.encode_field(:x, "cluster_feature_1", type: :quantitative)
  |> Vl.encode_field(:y, "cluster_feature_2", type: :quantitative)
])
```

```elixir
# use the mode to do prediction

test_preds = Scholar.Cluster.KMeans.predict(model, test_inputs)
```

```elixir
# find the model accuracy

Scholar.Metrics.Classification.accuracy(test_targets, test_preds)
```
